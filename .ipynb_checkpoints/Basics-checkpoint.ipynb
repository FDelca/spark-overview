{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2de1c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:27:34.505784Z",
     "start_time": "2022-05-25T17:27:34.502298Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/fdelca/Documents/spark/spark-2.1.2-bin-hadoop2.7')\n",
    "\n",
    "import pyspark\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7f66c",
   "metadata": {},
   "source": [
    "### Start a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7bf637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:23:18.087640Z",
     "start_time": "2022-05-25T17:23:18.083869Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b79534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:23:47.510655Z",
     "start_time": "2022-05-25T17:23:45.648117Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/home/fdelca/Documents/spark/spark-2.1.2-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/05/25 18:23:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/25 18:23:46 WARN Utils: Your hostname, fdelca-XPS-13-9380 resolves to a loopback address: 127.0.1.1; using 192.168.1.133 instead (on interface wlp2s0)\n",
      "22/05/25 18:23:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cff442",
   "metadata": {},
   "source": [
    "## Spark DataFrames - Lesson 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145e2a5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef707b69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:27:49.329544Z",
     "start_time": "2022-05-25T17:27:47.923712Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(os.path.join('data','people.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3571d5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:28:07.388881Z",
     "start_time": "2022-05-25T17:28:06.972646Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fadc6f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:28:38.093639Z",
     "start_time": "2022-05-25T17:28:38.087022Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Know the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac45d95",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Depending on your datasource, spark can dtype everything as a string - be caution with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ec3d6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:30:55.317243Z",
     "start_time": "2022-05-25T17:30:55.312356Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c95e87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:31:21.783353Z",
     "start_time": "2022-05-25T17:31:21.589025Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary of your columns\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6940d801",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define Schema\n",
    "- Sometimes we need to clarify the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16dd3107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:33:53.903274Z",
     "start_time": "2022-05-25T17:33:53.899116Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb4d6ced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:35:34.114678Z",
     "start_time": "2022-05-25T17:35:34.109687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_schema = [\n",
    "    StructField('age', IntegerType(), True), #Column name, Class instance (integer type), T/F can it be null?\n",
    "    StructField('name', StringType(), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e90d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:35:54.517082Z",
     "start_time": "2022-05-25T17:35:54.513496Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f101cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:36:42.864236Z",
     "start_time": "2022-05-25T17:36:42.839861Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(os.path.join('data','people.json'), schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f2378b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:36:54.655946Z",
     "start_time": "2022-05-25T17:36:54.650500Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887013a7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f822a3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7779305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:39:21.466721Z",
     "start_time": "2022-05-25T17:39:21.460409Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a column object\n",
    "type(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125430d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:40:29.748598Z",
     "start_time": "2022-05-25T17:40:29.736781Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With select we can have a dataframe, and then we can add show() to see the column\n",
    "type(df.select('age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a9c96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:40:36.454476Z",
     "start_time": "2022-05-25T17:40:36.405433Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|null|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0593ea62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:41:54.503130Z",
     "start_time": "2022-05-25T17:41:54.464834Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=None, name='Michael')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first two rows\n",
    "df.head(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4aa3236b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:42:13.251409Z",
     "start_time": "2022-05-25T17:42:13.191438Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['age', 'name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a38b0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Create a dataframe with a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9071bb66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:43:29.587374Z",
     "start_time": "2022-05-25T17:43:29.542261Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+\n",
      "| age|   name|double_age|\n",
      "+----+-------+----------+\n",
      "|null|Michael|      null|\n",
      "|  30|   Andy|        60|\n",
      "|  19| Justin|        38|\n",
      "+----+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('double_age', df['age']*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8073486c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:43:53.349314Z",
     "start_time": "2022-05-25T17:43:53.306517Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab676ca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to save it to a new variable, it is not an inplace operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051006e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rename a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28066d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:44:51.977825Z",
     "start_time": "2022-05-25T17:44:51.930001Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|my_new_age|   name|\n",
      "+----------+-------+\n",
      "|      null|Michael|\n",
      "|        30|   Andy|\n",
      "|        19| Justin|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename a column\n",
    "df.withColumnRenamed('age', 'my_new_age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea35060",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Using Pure SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7c020",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Register the df as a temporary view in SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "733b5581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:46:33.575374Z",
     "start_time": "2022-05-25T17:46:33.462095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "422b73a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:47:11.312107Z",
     "start_time": "2022-05-25T17:47:11.302134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = spark.sql(\"SELECT * FROM people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4581f3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:47:17.874995Z",
     "start_time": "2022-05-25T17:47:17.831669Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac5836a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:47:41.909947Z",
     "start_time": "2022-05-25T17:47:41.876711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_results = spark.sql(\"SELECT * FROM people WHERE age=30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6eb37d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T17:47:47.069792Z",
     "start_time": "2022-05-25T17:47:46.996202Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e35ee1",
   "metadata": {},
   "source": [
    "## Spark DataFrames - Lesson 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dca31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
